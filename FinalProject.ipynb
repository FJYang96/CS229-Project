{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils as util\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = util.load_data('./data/warfarin_with_dose.csv')\n",
    "X = []\n",
    "y = []\n",
    "for point in raw_data:\n",
    "    feature, dose = util.patient_from_feature(point)\n",
    "    X.append(feature)\n",
    "    y.append(dose)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into train, val and test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Load the feature header\n",
    "#######################################################\n",
    "import csv\n",
    "\n",
    "# read the csv file\n",
    "feature_names = []\n",
    "with open('./data/header.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        feature_names.append(line)\n",
    "\n",
    "# Dirty tricks to clean up the feature names\n",
    "feature_names = feature_names[0]\n",
    "feature_names = list(map(lambda x: x.replace(' ', '_'), feature_names))\n",
    "feature_names[0] = 'PharmGKB_Subject_ID' # manual fix to remove a character in f...[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Load the dataframe into X; clean up some unnecessary columns \n",
    "####################################################################\n",
    "\n",
    "# Load data and process column names\n",
    "df = pd.read_csv('./data/warfarin_with_dose.csv', names = feature_names)\n",
    "#keep_default_na=False)\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "\n",
    "# Extract the label (Warfarin dose) from the rest of the features\n",
    "y = df.Therapeutic_Dose_of_Warfarin\n",
    "X = df.drop('Therapeutic_Dose_of_Warfarin',axis=1)\n",
    "feature_names.remove('Therapeutic_Dose_of_Warfarin')\n",
    "\n",
    "# Drop Subject_ID (irrelevant) and Medication (different to encode)\n",
    "X = X.drop('PharmGKB_Subject_ID',axis=1)\n",
    "X = X.drop('Medications',axis=1)\n",
    "feature_names.remove('PharmGKB_Subject_ID')\n",
    "feature_names.remove('Medications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Encode different features with numeric/label/onehot encodings \n",
    "####################################################################\n",
    "numeric_features = ['Height_(cm)',\n",
    "                    'Weight_(kg)',\n",
    "                    'Target_INR',\n",
    "                    'INR_on_Reported_Therapeutic_Dose_of_Warfarin',\n",
    "                    ]\n",
    "label_features =   ['Age',\n",
    "                    'Estimated_Target_INR_Range_Based_on_Indication']\n",
    "categorical_features = [f for f in feature_names \\\n",
    "                        if f not in numeric_features and f not in label_features]\n",
    "\n",
    "for feat in categorical_features:\n",
    "    X[feat] = X[feat].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "label_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='0-missing')),\n",
    "    ('ordinal', OrdinalEncoder())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('lab', label_transformer, label_features),\n",
    "        ('cat', categorical_transformer, categorical_features)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5528, 1783)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3938308838129855\n",
      "182.1669176159891\n",
      "31.52241807909605\n",
      "[ -2.62093731   0.07702587   0.16954881  -1.81663937   1.4910022\n",
      "   1.38656902  -1.06093184  -6.41899367  11.18164824  -5.79829658\n",
      " -10.09348135  -9.22958937 -19.87868406 -21.63813941  -4.36744505\n",
      "  -9.4548067  -17.66790743  -7.08903945]\n"
     ]
    }
   ],
   "source": [
    "# Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_regressor = LinearRegression(fit_intercept = True)\n",
    "lr_regressor.fit(X_train, y_train)\n",
    "print(lr_regressor.score(X_val, y_val))\n",
    "\n",
    "y_pred = lr_regressor.predict(X_val)\n",
    "print(mean_squared_error(y_val,y_pred))\n",
    "print(np.mean(y_val))\n",
    "coef = lr_regressor.coef_\n",
    "print(coef)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13329921820187896"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_regressor = SVR(kernel='rbf', gamma='auto')\n",
    "svm_regressor.fit(X_train, y_train)\n",
    "svm_regressor.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score \n",
      " [[ 0.85439884]\n",
      " [ 0.6486505 ]\n",
      " [ 0.39173633]\n",
      " [ 0.18051436]\n",
      " [ 0.02837724]\n",
      " [-0.02581761]\n",
      " [-0.03313661]]\n",
      "validation score \n",
      " [[-0.16914487]\n",
      " [ 0.18075103]\n",
      " [ 0.21441668]\n",
      " [ 0.13329922]\n",
      " [ 0.01565171]\n",
      " [-0.03543393]\n",
      " [-0.04245123]]\n"
     ]
    }
   ],
   "source": [
    "# SVM with various hyperparameters\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#initialise arrays to store the scores \n",
    "svm_score_train = np.zeros((7,1))\n",
    "svm_score_val = np.zeros((7,1))\n",
    "\n",
    "for i, C in enumerate((1000,100,10,1, 0.1, 0.01,0.001)):\n",
    "    svm_regressor = SVR(kernel='rbf', gamma='auto', C=C)\n",
    "    svm_regressor.fit(X_train,y_train)\n",
    "    svm_score_train[i,:] = svm_regressor.score(X_train,y_train)\n",
    "    svm_score_val[i,:] = svm_regressor.score(X_val,y_val)\n",
    "    \n",
    "print('training score \\n', svm_score_train)\n",
    "print('validation score \\n', svm_score_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score \n",
      " [[0.28313693]\n",
      " [0.36697994]\n",
      " [0.39537848]\n",
      " [0.39781377]\n",
      " [0.39786211]\n",
      " [0.39786264]\n",
      " [0.39786265]]\n",
      "validation score \n",
      " [[0.28077951]\n",
      " [0.36252903]\n",
      " [0.39041267]\n",
      " [0.39362977]\n",
      " [0.39381411]\n",
      " [0.39382924]\n",
      " [0.39383072]]\n",
      "182.22735732001104\n",
      "31.52241807909605\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#initialise arrays to store the scores \n",
    "ridge_score_train = np.zeros((7,1))\n",
    "ridge_score_val = np.zeros((7,1))\n",
    "\n",
    "for i, C in enumerate((1000,100,10,1, 0.1, 0.01,0.001)):\n",
    "    ridge_regressor = Ridge(alpha=C, fit_intercept = True)\n",
    "    ridge_regressor.fit(X_train,y_train)\n",
    "    ridge_score_train[i,:] = ridge_regressor.score(X_train,y_train)\n",
    "    ridge_score_val[i,:] = ridge_regressor.score(X_val,y_val)\n",
    "    \n",
    "print('training score \\n', ridge_score_train)\n",
    "print('validation score \\n', ridge_score_val)\n",
    "\n",
    "best_ridge = Ridge(alpha = 1, fit_intercept = True)\n",
    "best_ridge.fit(X_train,y_train)\n",
    "y_pred = best_ridge.predict(X_val)\n",
    "print(mean_squared_error(y_val,y_pred))\n",
    "print(np.mean(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score \n",
      " [[0.        ]\n",
      " [0.06638883]\n",
      " [0.1539467 ]\n",
      " [0.26538526]\n",
      " [0.37596028]\n",
      " [0.39758491]\n",
      " [0.39785987]]\n",
      "validation score \n",
      " [[-0.00081468]\n",
      " [ 0.06759243]\n",
      " [ 0.15332604]\n",
      " [ 0.26487317]\n",
      " [ 0.36701346]\n",
      " [ 0.39325069]\n",
      " [ 0.39379806]]\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#initialise arrays to store the scores \n",
    "lasso_score_train = np.zeros((7,1))\n",
    "lasso_score_val = np.zeros((7,1))\n",
    "\n",
    "for i, C in enumerate((1000,100,10,1, 0.1, 0.01,0.001)):\n",
    "    lasso_regressor = Lasso(alpha=C, fit_intercept = True)\n",
    "    lasso_regressor.fit(X_train,y_train)\n",
    "    lasso_score_train[i,:] = lasso_regressor.score(X_train,y_train)\n",
    "    lasso_score_val[i,:] = lasso_regressor.score(X_val,y_val)\n",
    "    \n",
    "print('training score \\n', lasso_score_train)\n",
    "print('validation score \\n', lasso_score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest accuracy score is 0.17605920453271334\n"
     ]
    }
   ],
   "source": [
    "# non-nested cross validation using RBF SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rbf = SVR(kernel='rbf')\n",
    "gammas = np.logspace(-6, 0, 7)\n",
    "params = {'gamma': gammas}\n",
    "gridcv = GridSearchCV(estimator=rbf, param_grid=params, cv=5)\n",
    "gridcv.fit(X_trainval, y_trainval)\n",
    "scores_mean = gridcv.cv_results_['mean_test_score']\n",
    "scores_sd = gridcv.cv_results_['std_test_score']\n",
    "print('highest accuracy score is',gridcv.best_score_)\n",
    "model = gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest accuracy score is 0.4007028547482021\n"
     ]
    }
   ],
   "source": [
    "# non-nested cross validation using Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge_regressor = Ridge(fit_intercept = True)\n",
    "params={'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01]}\n",
    "\n",
    "gridcv = GridSearchCV(estimator=ridge_regressor, param_grid=params, cv=10)\n",
    "gridcv.fit(X_trainval, y_trainval)\n",
    "scores_mean = gridcv.cv_results_['mean_test_score']\n",
    "scores_sd = gridcv.cv_results_['std_test_score']\n",
    "print('highest accuracy score is',gridcv.best_score_)\n",
    "model = gridcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229",
   "language": "python",
   "name": "cs229"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
